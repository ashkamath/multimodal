.. multimodal documentation master file, created by
   sphinx-quickstart on Tue Dec 22 16:27:43 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to multimodal documentation.
======================================

**multimodal** is a python library providing tools for vision and language research. 
It provides visual features commonly used for Captionning and Visual Question Answering tasks,
as well as datasets such as VQA. 

.. toctree::
   :maxdepth: 2
   :caption: Datasets

   source/datasets
   source/tokenizers

.. toctree::
   :maxdepth: 2
   :caption: Visual Features

   source/visual_features

.. toctree::
   :maxdepth: 1
   :caption: Other
   
   source/models
   source/cli



This library was developped by Corentin Dancette. If you have any new feature request
or want to report a bug, please open an issue on the github tracker, or submit a Pull Request.
