.. multimodal documentation master file, created by
   sphinx-quickstart on Tue Dec 22 16:27:43 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to multimodal documentation.
======================================

**multimodal** is a python library providing tools for vision and language research. 
It provides visual features commonly used for Captionning and Visual Question Answering tasks,
as well as datasets such as VQA. 

.. toctree::
   :maxdepth: 2
   :caption: Features

   visual_features/visual_features

.. toctree::
   :maxdepth: 2
   :caption: Datasets

   datasets/datasets

.. toctree::
   :maxdepth: 0
   :caption: Tokenizers

   datasets/tokenizers




This library was developped by Corentin Dancette. If you have any new feature request
or want to report a bug, please open an issue on the github tracker, or submit a Pull Request.
